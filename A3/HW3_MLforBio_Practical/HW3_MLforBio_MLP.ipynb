{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www-scf.usc.edu/~ghasemig/images/sharif.png' alt=\"SUT logo\" width=200 height=200 align=left class=\"saturate\" >\n",
    "\n",
    "<br>\n",
    "<font face=\"Times New Roman\">\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "    ML for Bioinformatics <br>\n",
    "<font color=2565AE size=5>\n",
    "    Computer Engineering Department <br>\n",
    "<font color=3C99D size=5>\n",
    "    Homework 3: Practical - Multi-Layer Perceptron (VAE) <br>\n",
    "<font color=696880 size=4>\n",
    "    Sobhan Moghimi (sobhanmoghimi45@gmail.com) <br>\n",
    "    Fakhredin Abdi (fakhredinabdi80@gmail.com) <br>\n",
    "    \n",
    "____\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Name : Javad Razi\n",
    "### Student Number : 401204354\n",
    "__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Hnkccv8vVT-o"
   },
   "source": [
    "# Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A9Itv81cfTG4"
   },
   "source": [
    "**In this assignment you'll be working with Dorothea Dataset.**\n",
    "\n",
    "DOROTHEA is a drug discovery dataset. Chemical compounds represented by structural molecular features must be classified as active (binding to thrombin) or inactive.\n",
    "To find out more about dataset, refer to this link: https://archive.ics.uci.edu/ml/datasets/Dorothea\n",
    "\n",
    "You should implement a classifier with Neural Networks and for this purpose we will be using PyTorch as framework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zqSzHiJuUh7V"
   },
   "source": [
    "# Importing libraries, modules and Dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TlMDVS1gV08L"
   },
   "source": [
    "In this part, import all the libraries and modules needed to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WgjSY5BaViF2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random \n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RSBb23wYV2Ho"
   },
   "source": [
    "Now import the train and test data from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jNaH5szYV9Y4"
   },
   "outputs": [],
   "source": [
    "def download_and_save(url, file_path):\n",
    "    print(\"File doesn't exist locally. Going to download from \", url)\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "    print(\"File downloaded and stored in \", file_path)\n",
    "    \n",
    "    \n",
    "# Check if the CSV files exist in the ./data folder\n",
    "data_directory = \"./data/\"\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "train_data_file = \"dorothea_train.data\"\n",
    "train_labels_file = \"dorothea_train.labels\"\n",
    "test_data_file = \"dorothea_test.data\"\n",
    "\n",
    "urls = {\n",
    "    train_data_file: \"https://archive.ics.uci.edu/ml/machine-learning-databases/dorothea/DOROTHEA/dorothea_train.data\",\n",
    "    train_labels_file: \"https://archive.ics.uci.edu/ml/machine-learning-databases/dorothea/DOROTHEA/dorothea_train.labels\",\n",
    "    test_data_file: \"https://archive.ics.uci.edu/ml/machine-learning-databases/dorothea/DOROTHEA/dorothea_test.data\",\n",
    "}\n",
    "\n",
    "for file_name, url in urls.items():\n",
    "    file_path = os.path.join(data_directory, file_name)\n",
    "    if not os.path.exists(file_path):\n",
    "        download_and_save(url, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape (800, 100000)\n",
      "Train Labels Shape (800,)\n",
      "Test Data Shape (208, 100000)\n"
     ]
    }
   ],
   "source": [
    "def load_sparse_matrix(file_path):\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    values = np.zeros(shape=(len(lines), 100000), dtype=int)\n",
    "\n",
    "    for ind, line in enumerate(lines):\n",
    "        vals = np.array(list(map(float, line.strip().split())), dtype=int)\n",
    "        for v in vals:\n",
    "            values[ind, v-1] = 1\n",
    "\n",
    "    return csr_matrix(values)\n",
    "\n",
    "def load_labels(file_path):\n",
    "    return np.fromfile(file_path, sep='\\r\\n')\n",
    "\n",
    "# Read the CSV files from local computer\n",
    "train_data = load_sparse_matrix(os.path.join(data_directory, train_data_file))\n",
    "train_labels = load_labels(os.path.join(data_directory, train_labels_file))\n",
    "test_data = load_sparse_matrix(os.path.join(data_directory, test_data_file))\n",
    "\n",
    "print(\"Train Data Shape\", train_data.shape)\n",
    "print(\"Train Labels Shape\", train_labels.shape)\n",
    "print(\"Test Data Shape\", test_data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RgEJNhp_UiEa"
   },
   "source": [
    "## Normalize\n",
    "You can normalize your data using <code>Scikit-Learn</code> modules here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pQVOozI3Gjdv"
   },
   "source": [
    "## Dimensionality Reduction\n",
    "There are too many attributes for each instance of dataset. We will suffer from sparse data and long training phase. Thus you can reduce dimensions to get better accuracy. \n",
    "\n",
    "Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data.\n",
    "\n",
    "Apply PCA on Dorothea dataSet using <code>Scikit-Learn</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "wrdakV-5ZsRP"
   },
   "outputs": [],
   "source": [
    "# Apply PCA here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jFTEH0H23BtL"
   },
   "source": [
    "# Define Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "1z8_ahC_3S5f"
   },
   "outputs": [],
   "source": [
    "# Define your model in here\n",
    "# You can change the code below.\n",
    "\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IGUFUbsw3n9A"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YDrS8le13n25"
   },
   "source": [
    "**Initialize model, define hyperparameters, optimizer, loss function, etc.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "YV0FgUYc4J-Y"
   },
   "outputs": [],
   "source": [
    "# Implement Train in here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "L2Fnamnk4LTV"
   },
   "source": [
    "**After the training process, plot metrics such as loss function values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "3br2A_3x7tLY"
   },
   "outputs": [],
   "source": [
    "# Plot in here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vbwXdL9Ph2jD"
   },
   "source": [
    "# Testing\n",
    "After training, test your model on test dataset and compute performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "hzuhWfc3ia5s"
   },
   "outputs": [],
   "source": [
    "# Implement Test in here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vqQpZsTEh2gL"
   },
   "source": [
    "Show confusion matrix of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Kl9VOLgdiFMg"
   },
   "outputs": [],
   "source": [
    "# Print your confusion matrix here.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Hnkccv8vVT-o",
    "RgEJNhp_UiEa",
    "pQVOozI3Gjdv",
    "jFTEH0H23BtL",
    "IGUFUbsw3n9A",
    "vbwXdL9Ph2jD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
